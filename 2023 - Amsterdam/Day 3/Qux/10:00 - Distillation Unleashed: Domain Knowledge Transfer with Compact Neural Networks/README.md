# Distillation Unleashed: Domain Knowledge Transfer with Compact Neural Networks
by Hadi Abdi Khojasteh
* [Talk info](https://amsterdam2023.pydata.org/cfp/talk/3JEKJZ/)
## Abstract
This talk explores distillation learning, a powerful technique for compressing and transferring knowledge from larger neural networks to smaller, more efficient ones. It delves into its core components and various applications such as model compression and transfer learning. The speaker aims to simplify the topic for all audiences and provides implementation, demonstrating how to apply distillation learning in real scenarios. Attendees will gain insights into developing efficient neural networks by reviewing the various examples of the complex model. The material will be accessible online for convenient access and understanding.
